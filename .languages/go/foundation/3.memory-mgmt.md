# Go Memory Management

## Overview
Go provides automatic memory management through garbage collection, making it safe and efficient while abstracting away manual memory management complexities.

## Memory Layout

### Program Memory Structure
```
Stack Memory (per goroutine):
- Function parameters
- Local variables
- Return addresses
- Small values/primitives

Heap Memory (shared):
- Dynamically allocated objects
- Large objects
- Objects that escape scope
- Shared data structures
```

### Variable Storage Decisions

#### Stack Allocation
Variables stored on the stack when:
- Local to function and don't escape
- Size known at compile time
- Short lifetime (function scope)

```go
func stackExample() {
    x := 42        // Stack allocated
    arr := [10]int{} // Stack allocated (array)
}
```

#### Heap Allocation
Variables allocated on heap when:
- Returned from function (escape analysis)
- Too large for stack
- Size unknown at compile time
- Shared between goroutines

```go
func heapExample() *int {
    x := 42
    return &x  // x escapes to heap
}

func largeAlloc() {
    slice := make([]int, 1000000) // Large allocation goes to heap
}
```

## Garbage Collection

### Tri-Color Concurrent Mark & Sweep
Go uses a concurrent, tri-color, mark-and-sweep garbage collector:

1. **White**: Objects not yet visited
2. **Gray**: Objects visited but children not scanned
3. **Black**: Objects and their children fully processed

### GC Phases
```
1. Sweep Termination: Finish previous sweep
2. Mark Phase: Mark reachable objects
3. Mark Termination: Complete marking
4. Sweep Phase: Reclaim unmarked objects
```

### GC Tuning

#### Environment Variables
```bash
# Enable GC debugging
GODEBUG=gctrace=1

# Set GC target percentage
GOGC=100  # Default: trigger GC when heap doubles

# Set memory limit (Go 1.19+)
GOMEMLIMIT=4GiB
```

#### Programmatic Control
```go
import (
    "runtime"
    "runtime/debug"
)

// Force garbage collection
runtime.GC()

// Get GC stats
var stats runtime.MemStats
runtime.ReadMemStats(&stats)
fmt.Printf("Heap size: %d bytes\n", stats.HeapInuse)

// Set GC target
debug.SetGCPercent(50)  // GC when heap grows 50%

// Set memory limit
debug.SetMemoryLimit(1 << 30)  // 1GB limit
```

## Memory Allocation Patterns

### Make vs New

#### make() - For Reference Types
```go
// make initializes and returns ready-to-use reference types
slice := make([]int, 10, 20)    // length=10, capacity=20
mp := make(map[string]int)      // empty map
ch := make(chan int, 5)         // buffered channel
```

#### new() - For Value Types
```go
// new allocates zeroed memory and returns pointer
ptr := new(int)         // *int, value is 0
structPtr := new(User)  // *User, all fields zero values
```

### Slice Memory Management

#### Slice Growth
```go
func sliceGrowth() {
    s := make([]int, 0, 1)
    
    for i := 0; i < 10; i++ {
        fmt.Printf("len=%d cap=%d\n", len(s), cap(s))
        s = append(s, i)
    }
    // Growth pattern: 1 -> 2 -> 4 -> 8 -> 16 (roughly doubles)
}
```

#### Memory Leaks with Slices
```go
// Bad: Keeps entire underlying array in memory
func badSliceUsage(data []byte) []byte {
    return data[100:110]  // Small slice holds large array
}

// Good: Copy to new backing array
func goodSliceUsage(data []byte) []byte {
    result := make([]byte, 10)
    copy(result, data[100:110])
    return result  // Original data can be GC'd
}
```

### Map Memory Management

#### Map Growth and Shrinking
```go
m := make(map[string]int)

// Maps grow dynamically but never shrink automatically
for i := 0; i < 1000000; i++ {
    m[fmt.Sprintf("key%d", i)] = i
}

// Deleting doesn't shrink the map
for key := range m {
    delete(m, key)
}
// Memory still allocated

// Force shrinking by creating new map
if len(m) == 0 {
    m = make(map[string]int)
}
```

### Channel Memory Management

#### Channel Lifecycle
```go
// Unbuffered channel
ch := make(chan int)

// Buffered channel with memory allocated
ch := make(chan string, 1000)

// Close channel to signal completion
close(ch)

// Set to nil to help GC
ch = nil
```

## Memory Optimization Techniques

### Object Pooling

#### sync.Pool
```go
import "sync"

var pool = sync.Pool{
    New: func() interface{} {
        return make([]byte, 0, 1024)
    },
}

func processData(data []byte) {
    // Get from pool
    buf := pool.Get().([]byte)
    buf = buf[:0]  // Reset length
    
    // Use buffer
    buf = append(buf, data...)
    
    // Process buf...
    
    // Return to pool
    pool.Put(buf)
}
```

#### Custom Object Pool
```go
type BufferPool struct {
    pool chan *bytes.Buffer
}

func NewBufferPool(size int) *BufferPool {
    return &BufferPool{
        pool: make(chan *bytes.Buffer, size),
    }
}

func (p *BufferPool) Get() *bytes.Buffer {
    select {
    case buf := <-p.pool:
        buf.Reset()
        return buf
    default:
        return new(bytes.Buffer)
    }
}

func (p *BufferPool) Put(buf *bytes.Buffer) {
    select {
    case p.pool <- buf:
    default:
        // Pool full, let GC handle it
    }
}
```

### Memory Reuse Patterns

#### Preallocate Slices
```go
// Bad: Multiple allocations
func badAppend(items []string) []string {
    var result []string
    for _, item := range items {
        result = append(result, process(item))
    }
    return result
}

// Good: Single allocation
func goodAppend(items []string) []string {
    result := make([]string, 0, len(items))
    for _, item := range items {
        result = append(result, process(item))
    }
    return result
}
```

#### Struct Field Ordering
```go
// Bad: 32 bytes on 64-bit system due to padding
type BadStruct struct {
    flag1 bool     // 1 byte + 7 padding
    count int64    // 8 bytes
    flag2 bool     // 1 byte + 7 padding
    value int64    // 8 bytes
}

// Good: 18 bytes on 64-bit system
type GoodStruct struct {
    count int64    // 8 bytes
    value int64    // 8 bytes
    flag1 bool     // 1 byte
    flag2 bool     // 1 byte + 0 padding
}
```

## Memory Profiling and Analysis

### Using pprof

#### In Application
```go
import (
    _ "net/http/pprof"
    "net/http"
    "log"
)

func main() {
    go func() {
        log.Println(http.ListenAndServe("localhost:6060", nil))
    }()
    
    // Your application code
}
```

#### Memory Profiling
```bash
# Generate heap profile
go tool pprof http://localhost:6060/debug/pprof/heap

# Generate alloc profile  
go tool pprof http://localhost:6060/debug/pprof/allocs

# Interactive commands in pprof
(pprof) top          # Show top memory users
(pprof) list main.   # Show source code with allocations
(pprof) web          # Visual graph in browser
```

#### Programmatic Profiling
```go
import (
    "os"
    "runtime/pprof"
)

// Start memory profiling
f, err := os.Create("mem.prof")
if err != nil {
    log.Fatal(err)
}
defer f.Close()

runtime.GC() // Force GC before profiling
if err := pprof.WriteHeapProfile(f); err != nil {
    log.Fatal(err)
}
```

### Memory Monitoring

#### Runtime Statistics
```go
func printMemStats() {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    
    fmt.Printf("Alloc = %d KB", bToKb(m.Alloc))
    fmt.Printf("TotalAlloc = %d KB", bToKb(m.TotalAlloc))
    fmt.Printf("Sys = %d KB", bToKb(m.Sys))
    fmt.Printf("NumGC = %v\n", m.NumGC)
}

func bToKb(b uint64) uint64 {
    return b / 1024
}
```

#### Custom Metrics Collection
```go
type MemoryTracker struct {
    mu       sync.RWMutex
    baseline runtime.MemStats
    samples  []runtime.MemStats
}

func (mt *MemoryTracker) Snapshot() {
    mt.mu.Lock()
    defer mt.mu.Unlock()
    
    var m runtime.MemStats
    runtime.ReadMemStats(&m)
    mt.samples = append(mt.samples, m)
}

func (mt *MemoryTracker) Report() {
    mt.mu.RLock()
    defer mt.mu.RUnlock()
    
    if len(mt.samples) == 0 {
        return
    }
    
    latest := mt.samples[len(mt.samples)-1]
    fmt.Printf("Memory Report:\n")
    fmt.Printf("  Heap: %d bytes\n", latest.HeapInuse)
    fmt.Printf("  GC Cycles: %d\n", latest.NumGC)
}
```

## Memory Safety

### Race Detection
```bash
# Build with race detector
go build -race

# Run tests with race detection
go test -race

# Run program with race detection
go run -race main.go
```

### Preventing Memory Leaks

#### Context Cancellation
```go
ctx, cancel := context.WithCancel(context.Background())
defer cancel()

// Pass context to prevent goroutine leaks
go worker(ctx)
```

#### Closing Channels
```go
func producer(ch chan<- int) {
    defer close(ch)  // Always close channels you create
    
    for i := 0; i < 10; i++ {
        ch <- i
    }
}
```

#### Timer Cleanup
```go
timer := time.NewTimer(time.Hour)
defer timer.Stop()  // Prevent timer leak

// For time.After, use context for cancellation
ctx, cancel := context.WithTimeout(context.Background(), time.Hour)
defer cancel()

select {
case <-ctx.Done():
    // Timeout
case result := <-someChannel:
    // Got result
}
```

## Advanced Memory Techniques

### Memory-Mapped Files
```go
import "golang.org/x/exp/mmap"

func readLargeFile(filename string) error {
    r, err := mmap.Open(filename)
    if err != nil {
        return err
    }
    defer r.Close()
    
    // Read without loading entire file into memory
    data := make([]byte, 1024)
    n, err := r.ReadAt(data, 0)
    if err != nil && err != io.EOF {
        return err
    }
    
    // Process data[:n]
    return nil
}
```

### Unsafe Memory Operations
```go
import "unsafe"

// Convert string to []byte without copying
func stringToBytes(s string) []byte {
    return (*[0x7fff0000]byte)(unsafe.Pointer(
        (*reflect.StringHeader)(unsafe.Pointer(&s)).Data),
    )[:len(s):len(s)]
}

// Use with extreme caution!
func unsafeExample() {
    s := "hello"
    b := stringToBytes(s)
    // b shares memory with s - modifications affect both
}
```

## Best Practices

### 1. Prefer Stack Allocation
```go
// Good: Stack allocated
func processSmallData() {
    data := [100]byte{}  // Array on stack
    // Process data
}

// Avoid unnecessary heap allocation
func avoidEscaping() int {
    x := 42
    // Don't return &x unless necessary
    return x
}
```

### 2. Reuse Memory When Possible
```go
type Processor struct {
    buffer []byte
}

func (p *Processor) Process(data []byte) {
    // Reuse buffer
    if cap(p.buffer) < len(data) {
        p.buffer = make([]byte, len(data))
    }
    p.buffer = p.buffer[:len(data)]
    copy(p.buffer, data)
    // Process p.buffer
}
```

### 3. Be Mindful of Closures
```go
// Bad: Closure captures entire large slice
func badClosures(data []LargeStruct) []func() {
    var funcs []func()
    for i := range data {
        funcs = append(funcs, func() {
            // This captures the entire data slice
            fmt.Println(data[i])
        })
    }
    return funcs
}

// Good: Copy only what's needed
func goodClosures(data []LargeStruct) []func() {
    var funcs []func()
    for i := range data {
        item := data[i]  // Copy item
        funcs = append(funcs, func() {
            fmt.Println(item)
        })
    }
    return funcs
}
```

### 4. Monitor Memory Usage
```go
func monitorMemory(ctx context.Context) {
    ticker := time.NewTicker(30 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            var m runtime.MemStats
            runtime.ReadMemStats(&m)
            log.Printf("Memory: %d KB, GC: %d", m.Alloc/1024, m.NumGC)
        }
    }
}
```

## References
- [Go Memory Model](https://go.dev/ref/mem)
- [Garbage Collection Guide](https://tip.golang.org/doc/gc-guide)
- [Memory Profiling](https://go.dev/blog/pprof)
- [Escape Analysis](https://github.com/golang/go/wiki/CompilerOptimizations)